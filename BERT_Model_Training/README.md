# Model Training with RoBERTa and DeBERTa

This repository demonstrates the training of **RoBERTa** and **DeBERTa** models for a binary classification task using transformer-based architectures. The project includes data preprocessing, model fine-tuning, and evaluation with metrics such as accuracy, precision, recall, and F1-score.

---

## Included Files

  - `Roberta_Train.ipynb`: Notebook for training the **RoBERTa** model.
  - `Deberta_Train.ipynb`: Notebook for training the **DeBERTa** model.

---

## Overview of Notebooks

### 1. **RoBERTa Training (`Roberta_Train.ipynb`)**
### 2. **DeBERTa Training (`Deberta_Train.ipynb`)**

Notebook outlines:
- Loading and tokenizing the dataset for the model.
- Setting up training parameters, including batch size and learning rate.
- Fine-tuning the model with evaluation at each epoch.
- Evaluating performance metrics (accuracy, precision, recall, F1-score).
- Saving and exporting the fine-tuned model.
