{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4782a2-b6b6-4f93-a479-cacdc1d405ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488cf35-740a-441f-814c-2f66fd53cbf6",
   "metadata": {},
   "source": [
    "### Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0484cc8c-b432-46f4-b6b2-9a736a91af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1071e-c380-4841-a475-46ad7f7ea3b3",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39900add-7839-4935-9afa-b79136dfa2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./model/roberta-base/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model_dir = \"./model/roberta-base/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta_model_dir)\n",
    "model = RobertaForSequenceClassification.from_pretrained(roberta_model_dir, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccafd36-76cf-4057-8779-2916f26c44d1",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e770b21-eb20-49e8-8fa3-3aeb4763df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/clean_train.csv\")\n",
    "test_data = pd.read_csv(\"./data/clean_test.csv\")\n",
    "train_data['label'] = train_data['target']\n",
    "dataset = Dataset.from_pandas(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05fd47de-07cb-4f6f-a7b6-a4d2d8a3416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/clean_final_dataset.csv\")\n",
    "data['label'] = data['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f168412-bf58-4bc8-8ff9-c676e27056c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aceaf386d3a4420aa3159d1dac2d8fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5374\n",
      "Eval dataset size: 1344\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "# Define the preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=200)\n",
    "\n",
    "# Preprocess the dataset\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
    "\n",
    "# Set the dataset format for PyTorch\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "train_test_split = encoded_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c32ebf-3d2e-4987-b340-10d99345fa28",
   "metadata": {},
   "source": [
    "### Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eff49b0-dbe1-4b5a-bbc7-d3208ce5bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/zhaolinz/.conda/envs/conda-env/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./RoBERTa_results',\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    #gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    #num_train_epochs=2,\n",
    "    max_steps=200,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,  # Enable mixed precision training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7ae4a-c598-427b-9aa5-fae5ee7c58d9",
   "metadata": {},
   "source": [
    "### Define compute metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab6ece7-cc64-4f4d-b4cd-74de1b585743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f868d-adbc-4815-9fde-822aed95a2c9",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f188892c-119c-41e5-9396-fd94ee0e266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92344a39-aeaa-4da2-ae5b-3553195c3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd92db9-7205-459e-8821-e44b2d8f37b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:16, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.387184</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.822612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.45067530155181884, metrics={'train_runtime': 16.981, 'train_samples_per_second': 94.223, 'train_steps_per_second': 11.778, 'total_flos': 164444409600000.0, 'train_loss': 0.45067530155181884, 'epoch': 0.2976190476190476})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f91d6d-e107-4eec-8642-a4be804b9c4c",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18866564-6a4b-44d9-8030-cb0fd7563c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3871840834617615, 'eval_accuracy': 0.8645833333333334, 'eval_precision': 0.8084291187739464, 'eval_recall': 0.8373015873015873, 'eval_f1': 0.8226120857699805, 'eval_runtime': 3.5261, 'eval_samples_per_second': 381.154, 'eval_steps_per_second': 95.288, 'epoch': 0.2976190476190476}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17845d57-dae9-4461-86a9-8c5885f14e60",
   "metadata": {},
   "source": [
    "### RoBERTa Result\n",
    "##### Self-Extracted Dataset:\n",
    "- train_batch_size: 8\n",
    "- epoch: 2\n",
    "- acc: 0.8646\n",
    "- precision: 0.8084\n",
    "- recall: 0.8373\n",
    "- f1: 0.8226"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a8525-505e-4227-a11e-27cc25bf6ec5",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de09c9da-c881-4f4d-b18b-62337c215885",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./data/tweets_testset.csv\")\n",
    "test_data['label'] = test_data['label'].astype('int64')\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6da8e565-6a1f-40a6-b835-80a75b014c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c1e0d7d9444f608c4ffb225224b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_new_test_dataset = test_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
    "encoded_new_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbcae629-3f0c-4a72-95aa-a2c6adc3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(encoded_new_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a703962-c13a-4ad2-a667-fd490d440748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.5888678431510925, 'test_accuracy': 0.856687898089172, 'test_precision': 0.5925925925925926, 'test_recall': 0.9846153846153847, 'test_f1': 0.7398843930635838, 'test_runtime': 0.8843, 'test_samples_per_second': 355.083, 'test_steps_per_second': 89.336}\n"
     ]
    }
   ],
   "source": [
    "print(predictions.metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76d287-c79f-4799-b040-d69fe267c98a",
   "metadata": {},
   "source": [
    "- acc: 0.8567\n",
    "- precision: 0.5926\n",
    "- recall: 0.9846\n",
    "- f1: 0.7399"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd5259-34c8-49ed-bb0c-862a113f2919",
   "metadata": {},
   "source": [
    "### BadCase Output - Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "587bf51e-8044-419b-a4ee-20c5450d9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = predictions.label_ids\n",
    "predicted_labels = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "276d6c7d-d763-4df4-ad07-a16585d41cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_case_indices = [i for i, (true, pred) in enumerate(zip(true_labels, predicted_labels)) if true != pred]\n",
    "bad_cases = [eval_dataset[i] for i in bad_case_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bb56ee3-4c6e-41e2-b9ac-7b5c490244c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_case_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43e41908-7167-4164-b5a8-002986fe1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_list = []\n",
    "true_label = []\n",
    "predicted_label = []\n",
    "for idx, case in enumerate(bad_cases):\n",
    "    bad_list.append(tokenizer.decode(case['input_ids'], skip_special_tokens=True))\n",
    "    true_label.append(true_labels[bad_case_indices[idx]])\n",
    "    predicted_label.append(predicted_labels[bad_case_indices[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "230b4293-74de-4695-8483-fd434f1653d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df = pd.DataFrame({\n",
    "    'Text': bad_list,\n",
    "    'True_Label': true_label,\n",
    "    'Predicted_Label': predicted_label\n",
    "})\n",
    "df.to_csv('./bad_case/RoBERTa_bad_case.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a63a9-eefe-4731-bdd1-5a201c3ad0b6",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b2eb2-f7a0-43e9-8568-6f16cc5a3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './RoBERTa_downloads/result'\n",
    "if trainer.model is not None:\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    print(f\"Model saved to {output_dir}\")\n",
    "else:\n",
    "    print(\"Trainer model Load ERROR\")\n",
    "\n",
    "if tokenizer is not None:\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"Tokenizer saved to {output_dir}\")\n",
    "else:\n",
    "    print(\"Trainer tokenizer Load ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6b9c3-c15b-4bb7-bc31-8261ea57d0a1",
   "metadata": {},
   "source": [
    "#### To Use Saved Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e4b85-b1e7-4bc6-97ab-41038860c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = './RoBERTa_downloads/result' # Replace with your model's save directory\n",
    "try:\n",
    "    model = RobertaForSequenceClassification.from_pretrained(saved_model_dir)\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(saved_model_dir)\n",
    "    print(\"Model and tokenizer reloaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reloading model or tokenizer: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec950bd-90e4-45e0-a840-798e47da6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d08d4-4464-415b-bac2-5837c8cc685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_data:\n",
    "        inputs = {key: batch[key].to(device) for key in ['input_ids', 'attention_mask']}\n",
    "        outputs = model(**inputs)  # Forward pass\n",
    "        logits = outputs.logits  # Logits output\n",
    "        batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()  # Get predicted class indices\n",
    "        predictions.extend(batch_predictions)  # Store predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
